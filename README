This is bot scraper for crime arrests at the University of Maryland, Baltimore.

March 27th, 2023:
    I started taking the first few steps of grabbing the information from UMB's 60-Day Crime and Fire Log. The tutorial from class was extremely helpful, as it provided the libraries I'd use to scrape the information. I needed to grab the daat from the 'p' tags on the website. I had to put my information into a list and do some minor text parsing. For example, when I printed the crimes and fires I was scraping for from the website, the text had "\xa0" in it. So that needed to be removed. I then put all the data together into my list and wrote it out as a CSV. 

April 2, 2023:
    I've added more things and have removed some other stuff too! I've created a dictionary of the key/column names, so that Python understands the value attached to each column name/key. It allows for easy calling of specific values of the data. I've also created a yml file to make the bot run on it's own. The whole thing is acting a little weird because it won't let me commit my changes. 

April 3, 2023:
    Because some of my changes/creations were made locally and on Github, this led to the non-committing. So I had to delete the codespaces and start again with what I committed back on April 2nd. 

April 5th, 2023:
    We're getting somewhere. I have now added in my slack information. It's doing the printing I need it to do, however, it looks like I'll need to clean up the text. 

April 8th 2023:
    Looking a lot better! I redid my csv-creation code because it was printing just the column names... not doing that anymore! I also lower-cased some of the text in specific keys/column names such as incident, disposition and synopsis. I also edited the text in the messages for it to look a little prettier. I'd say that I'm pretty confident in submitting this!

Issues I'm Still Having:
- Everytime I run the code, it creates duplicates to the csv. I asked Chat GPT for some help but I'm still running into some roadblocks. I definitely plan on revisiting this issue. 